{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import email\n",
    "from generate_data import generate_train_and_test_data\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\n",
      "Date: Fri, 4 May 2001 13:51:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: john.lavorato@enron.com\n",
      "Subject: Re:\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\n",
      "\n",
      "As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \n",
      "\n",
      "My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emails = pd.read_csv('data/emails.csv',quoting=2,header=0)\n",
    "emails = emails[emails[\"file\"].str.contains('sent').tolist()]\n",
    "filelist = emails['file'].tolist()\n",
    "messages = emails['message'].tolist()\n",
    "msg = email.message_from_string(messages[1])\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### these are the 10 people whose writing styles we will analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list=['kay.mann@enron.com','vince.kaminski@enron.com','jeff.dasovich@enron.com',\n",
    "                 'chris.germany@enron.com','sara.shackleton@enron.com','tana.jones@enron.com',\n",
    "                'eric.bass@enron.com','matthew.lenhart@enron.com','kate.symes@enron.com','sally.beck@enron.com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the enron emails often contain forwarded messages, or the orginal text in a reply to email. we remove all this data since we are trying to understand a particular person's writing style.\n",
    "#### we also split the data into train and test. the test data is what we will try and predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,df_train,df_test=generate_train_and_test_data('data/emails.csv',filter_list,min_words=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40027, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FormattedMessage</th>\n",
       "      <th>MessageLength</th>\n",
       "      <th>NumWords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chris.germany@enron.com</th>\n",
       "      <td>4560</td>\n",
       "      <td>236.905921</td>\n",
       "      <td>44.401535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eric.bass@enron.com</th>\n",
       "      <td>2678</td>\n",
       "      <td>144.328603</td>\n",
       "      <td>28.281927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeff.dasovich@enron.com</th>\n",
       "      <td>4784</td>\n",
       "      <td>435.320025</td>\n",
       "      <td>72.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kate.symes@enron.com</th>\n",
       "      <td>2617</td>\n",
       "      <td>307.330149</td>\n",
       "      <td>53.588460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kay.mann@enron.com</th>\n",
       "      <td>8163</td>\n",
       "      <td>202.101188</td>\n",
       "      <td>35.149455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthew.lenhart@enron.com</th>\n",
       "      <td>2545</td>\n",
       "      <td>107.922593</td>\n",
       "      <td>23.260904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sally.beck@enron.com</th>\n",
       "      <td>2461</td>\n",
       "      <td>490.861032</td>\n",
       "      <td>92.376676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara.shackleton@enron.com</th>\n",
       "      <td>3950</td>\n",
       "      <td>254.070380</td>\n",
       "      <td>42.507342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tana.jones@enron.com</th>\n",
       "      <td>3307</td>\n",
       "      <td>241.613245</td>\n",
       "      <td>43.262474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vince.kaminski@enron.com</th>\n",
       "      <td>4962</td>\n",
       "      <td>168.216647</td>\n",
       "      <td>29.316808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FormattedMessage  MessageLength   NumWords\n",
       "From                                                                 \n",
       "chris.germany@enron.com                4560     236.905921  44.401535\n",
       "eric.bass@enron.com                    2678     144.328603  28.281927\n",
       "jeff.dasovich@enron.com                4784     435.320025  72.006689\n",
       "kate.symes@enron.com                   2617     307.330149  53.588460\n",
       "kay.mann@enron.com                     8163     202.101188  35.149455\n",
       "matthew.lenhart@enron.com              2545     107.922593  23.260904\n",
       "sally.beck@enron.com                   2461     490.861032  92.376676\n",
       "sara.shackleton@enron.com              3950     254.070380  42.507342\n",
       "tana.jones@enron.com                   3307     241.613245  43.262474\n",
       "vince.kaminski@enron.com               4962     168.216647  29.316808"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_summary=df.pivot_table(index=\"From\",values='FormattedMessage',aggfunc=\"count\")\n",
    "df_2=df.pivot_table(index=\"From\",values=['NumWords','MessageLength'],aggfunc=\"mean\")\n",
    "df_summary=df_summary.join(df_2,lsuffix='',rsuffix='')\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chris.germany@enron.com</th>\n",
       "      <td>44.401535</td>\n",
       "      <td>43.816232</td>\n",
       "      <td>49.656455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eric.bass@enron.com</th>\n",
       "      <td>28.281927</td>\n",
       "      <td>28.867194</td>\n",
       "      <td>23.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeff.dasovich@enron.com</th>\n",
       "      <td>72.006689</td>\n",
       "      <td>72.068885</td>\n",
       "      <td>71.457906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kate.symes@enron.com</th>\n",
       "      <td>53.588460</td>\n",
       "      <td>53.593683</td>\n",
       "      <td>53.543796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kay.mann@enron.com</th>\n",
       "      <td>35.149455</td>\n",
       "      <td>34.767816</td>\n",
       "      <td>38.548544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthew.lenhart@enron.com</th>\n",
       "      <td>23.260904</td>\n",
       "      <td>23.253673</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sally.beck@enron.com</th>\n",
       "      <td>92.376676</td>\n",
       "      <td>93.174482</td>\n",
       "      <td>85.094650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara.shackleton@enron.com</th>\n",
       "      <td>42.507342</td>\n",
       "      <td>42.317634</td>\n",
       "      <td>44.274151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tana.jones@enron.com</th>\n",
       "      <td>43.262474</td>\n",
       "      <td>42.921496</td>\n",
       "      <td>46.247788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vince.kaminski@enron.com</th>\n",
       "      <td>29.316808</td>\n",
       "      <td>29.240778</td>\n",
       "      <td>30.012270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 All      Train       Test\n",
       "From                                                      \n",
       "chris.germany@enron.com    44.401535  43.816232  49.656455\n",
       "eric.bass@enron.com        28.281927  28.867194  23.188406\n",
       "jeff.dasovich@enron.com    72.006689  72.068885  71.457906\n",
       "kate.symes@enron.com       53.588460  53.593683  53.543796\n",
       "kay.mann@enron.com         35.149455  34.767816  38.548544\n",
       "matthew.lenhart@enron.com  23.260904  23.253673  23.333333\n",
       "sally.beck@enron.com       92.376676  93.174482  85.094650\n",
       "sara.shackleton@enron.com  42.507342  42.317634  44.274151\n",
       "tana.jones@enron.com       43.262474  42.921496  46.247788\n",
       "vince.kaminski@enron.com   29.316808  29.240778  30.012270"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=df.pivot_table(index=\"From\",values='NumWords',aggfunc=\"mean\")\n",
    "train_data=df_train.pivot_table(index=\"From\",values='NumWords',aggfunc='mean')\n",
    "test_data=df_test.pivot_table(index=\"From\",values='NumWords',aggfunc='mean')\n",
    "df_summary=all_data.join(train_data,lsuffix='All',rsuffix='Train')\n",
    "df_summary=df_summary.join(test_data,lsuffix='',rsuffix='Test')\n",
    "df_summary.columns=['All','Train','Test']\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chris.germany@enron.com</th>\n",
       "      <td>236.905921</td>\n",
       "      <td>232.893736</td>\n",
       "      <td>272.927790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eric.bass@enron.com</th>\n",
       "      <td>144.328603</td>\n",
       "      <td>147.488759</td>\n",
       "      <td>116.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeff.dasovich@enron.com</th>\n",
       "      <td>435.320025</td>\n",
       "      <td>435.813591</td>\n",
       "      <td>430.965092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kate.symes@enron.com</th>\n",
       "      <td>307.330149</td>\n",
       "      <td>307.107981</td>\n",
       "      <td>309.229927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kay.mann@enron.com</th>\n",
       "      <td>202.101188</td>\n",
       "      <td>199.605396</td>\n",
       "      <td>224.330097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthew.lenhart@enron.com</th>\n",
       "      <td>107.922593</td>\n",
       "      <td>107.573466</td>\n",
       "      <td>111.419913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sally.beck@enron.com</th>\n",
       "      <td>490.861032</td>\n",
       "      <td>495.744364</td>\n",
       "      <td>446.288066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sara.shackleton@enron.com</th>\n",
       "      <td>254.070380</td>\n",
       "      <td>252.721615</td>\n",
       "      <td>266.631854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tana.jones@enron.com</th>\n",
       "      <td>241.613245</td>\n",
       "      <td>239.479784</td>\n",
       "      <td>260.292035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vince.kaminski@enron.com</th>\n",
       "      <td>168.216647</td>\n",
       "      <td>168.549966</td>\n",
       "      <td>165.167689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  All       Train        Test\n",
       "From                                                         \n",
       "chris.germany@enron.com    236.905921  232.893736  272.927790\n",
       "eric.bass@enron.com        144.328603  147.488759  116.826087\n",
       "jeff.dasovich@enron.com    435.320025  435.813591  430.965092\n",
       "kate.symes@enron.com       307.330149  307.107981  309.229927\n",
       "kay.mann@enron.com         202.101188  199.605396  224.330097\n",
       "matthew.lenhart@enron.com  107.922593  107.573466  111.419913\n",
       "sally.beck@enron.com       490.861032  495.744364  446.288066\n",
       "sara.shackleton@enron.com  254.070380  252.721615  266.631854\n",
       "tana.jones@enron.com       241.613245  239.479784  260.292035\n",
       "vince.kaminski@enron.com   168.216647  168.549966  165.167689"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=df.pivot_table(index=\"From\",values='MessageLength',aggfunc=\"mean\")\n",
    "train_data=df_train.pivot_table(index=\"From\",values='MessageLength',aggfunc='mean')\n",
    "test_data=df_test.pivot_table(index=\"From\",values='MessageLength',aggfunc='mean')\n",
    "df_summary=all_data.join(train_data,lsuffix='All',rsuffix='Train')\n",
    "df_summary=df_summary.join(test_data,lsuffix='',rsuffix='Test')\n",
    "df_summary.columns=['All','Train','Test']\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take all the text in the training set, and count the total number of words\n",
    "#### then take the text for each author and count the total number of words by author\n",
    "#### finally we take the n_most_frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1843025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "#this is the most frequent count\n",
    "n_most_frequent=50\n",
    "\n",
    "#define a dictionary to hold the word count for each author\n",
    "author_subcorpus_count={}\n",
    "for item in filter_list:\n",
    "    author_subcorpus_count[item]=defaultdict(int)\n",
    "\n",
    "\n",
    "all_text=df_train['FormattedMessage'].tolist()\n",
    "from_list=df_train['From'].tolist()\n",
    "\n",
    "#word counts for the combined corpus\n",
    "word_counts=defaultdict(int)\n",
    "\n",
    "#go through the entire corpus, count words for the combined corpus and for each author\n",
    "for i,text in enumerate(all_text):\n",
    "    sentences=sent_tokenize(text.lower())\n",
    "    for sentence in sentences:\n",
    "        words=word_tokenize(sentence)\n",
    "        fdist = nltk.FreqDist(words)\n",
    "        for word in fdist:\n",
    "            word_counts[word]+=fdist[word]\n",
    "            author_subcorpus_count[from_list[i]][word]+=fdist[word]\n",
    "            \n",
    "#create a list of most frequent words\n",
    "#also check what total word count is (to validate data)\n",
    "freq_list=[]\n",
    "i=0\n",
    "totalWords=0\n",
    "for w in word_counts:\n",
    "    totalWords+=word_counts[w]\n",
    "for w in sorted(word_counts, key=word_counts.get, reverse=True):\n",
    "    if i<n_most_frequent: freq_list.append((w,word_counts[w]))\n",
    "    i+=1\n",
    "totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 91894),\n",
       " ('the', 71283),\n",
       " (',', 66043),\n",
       " ('to', 51610),\n",
       " ('i', 42181),\n",
       " ('and', 29998),\n",
       " ('a', 26967),\n",
       " ('of', 24905),\n",
       " ('you', 24804),\n",
       " ('in', 20779),\n",
       " ('for', 19969),\n",
       " ('that', 18942),\n",
       " ('is', 18413),\n",
       " ('on', 15771),\n",
       " ('it', 15007),\n",
       " ('we', 14029),\n",
       " ('this', 13639),\n",
       " ('?', 13243),\n",
       " ('have', 13240),\n",
       " (')', 13030),\n",
       " ('be', 12821),\n",
       " ('with', 12696),\n",
       " ('(', 12492),\n",
       " (\"'s\", 11369),\n",
       " ('will', 10800),\n",
       " ('me', 9034),\n",
       " (':', 8671),\n",
       " ('are', 8539),\n",
       " ('at', 8228),\n",
       " ('if', 7999),\n",
       " ('thanks', 7689),\n",
       " (\"n't\", 7556),\n",
       " ('as', 7359),\n",
       " ('do', 7310),\n",
       " ('from', 6502),\n",
       " ('can', 6364),\n",
       " ('my', 6360),\n",
       " ('not', 6347),\n",
       " (\"''\", 6139),\n",
       " ('know', 6058),\n",
       " ('your', 5868),\n",
       " ('would', 5837),\n",
       " ('was', 5489),\n",
       " ('or', 5416),\n",
       " ('!', 5389),\n",
       " ('please', 5322),\n",
       " ('but', 5187),\n",
       " ('-', 5107),\n",
       " ('``', 5070),\n",
       " ('>', 4939)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843025\n"
     ]
    }
   ],
   "source": [
    "#aggregate total words by author\n",
    "#ensure it adds up to total words by corpus\n",
    "totalWordsByAuthor={}\n",
    "totalWords=0\n",
    "for author in author_subcorpus_count:\n",
    "    totalWordsByAuthor[author]=sum(author_subcorpus_count[author][x] for x in author_subcorpus_count[author])\n",
    "    totalWords+=totalWordsByAuthor[author]\n",
    "\n",
    "#we compute the mean for the corpus 2 ways\n",
    "#by corpus - so for example count \"the\" in the entire corpus/ total words in corpus\n",
    "#or compute the prob of \"the\" in each author's corpus and average it\n",
    "#the 2 results are not that different\n",
    "frequentWordsCorpusMean={}\n",
    "frequentWordsCorpusStdDev={}\n",
    "for word,count in freq_list:\n",
    "    frequentWordsCorpusMean[word]=(count+0.000001)/totalWords\n",
    "    frequentWordsCorpusStdDev[word]=0.0\n",
    "\n",
    "\n",
    "topWordsByAuthor={}\n",
    "for item in author_subcorpus_count:\n",
    "    topWordsByAuthor[item]={}\n",
    "    for word,count in freq_list:\n",
    "        wc=author_subcorpus_count[item][word]\n",
    "        wp=(wc+0.000001)/totalWordsByAuthor[item]\n",
    "        topWordsByAuthor[item][word]=wp\n",
    "        \n",
    "frequentWordsMean={}\n",
    "for word,count in freq_list:\n",
    "    frequentWordsMean[word]=0.0\n",
    "    for author in topWordsByAuthor:\n",
    "        frequentWordsMean[word]+=topWordsByAuthor[author][word]\n",
    "    frequentWordsMean[word]/=len(topWordsByAuthor)\n",
    "\n",
    "for word,count in freq_list:\n",
    "    for author in topWordsByAuthor:\n",
    "        diff=topWordsByAuthor[author][word]-frequentWordsCorpusMean[word]\n",
    "        frequentWordsCorpusStdDev[word]+=diff*diff\n",
    "    frequentWordsCorpusStdDev[word]/=len(topWordsByAuthor)\n",
    "    frequentWordsCorpusStdDev[word]=math.sqrt(frequentWordsCorpusStdDev[word])\n",
    "    \n",
    "#print(frequentWordsCorpusMean)\n",
    "print(totalWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate zscores\n",
    "#for each author, calculate the zscore for each of the common words\n",
    "zScoresByAuthor={}\n",
    "for author in topWordsByAuthor:\n",
    "    zScoresByAuthor[author]={}\n",
    "    for word in frequentWordsCorpusMean:\n",
    "        zScoresByAuthor[author][word]=(topWordsByAuthor[author][word]-frequentWordsCorpusMean[word])/(frequentWordsCorpusStdDev[word]+0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function calculates the zscore for the test text\n",
    "#it takes the text and counts the probabilities for common words\n",
    "#and uses the frequentWordsCorpusMean and frequentWordsCorpusStdDev\n",
    "def calc_z_score(text,frequentWordsCorpusMean,frequentWordsCorpusStdDev):\n",
    "    word_counts=defaultdict(int)\n",
    "    totalWords=0\n",
    "    sentences=sent_tokenize(text.lower())\n",
    "    for sentence in sentences:\n",
    "        words=word_tokenize(sentence)\n",
    "        fdist = nltk.FreqDist(words)\n",
    "        for word in frequentWordsCorpusMean:\n",
    "            if word in fdist:\n",
    "                word_counts[word]+=fdist[word]\n",
    "            else:\n",
    "                word_counts[word]+=0\n",
    "            totalWords+=fdist[word]\n",
    "    zScores={}\n",
    "    for word in word_counts:\n",
    "        word_dist=(word_counts[word]+0.000001)/(totalWords+0.000001)\n",
    "        zScores[word]=(word_dist-frequentWordsCorpusMean[word])/frequentWordsCorpusStdDev[word]\n",
    "    return zScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_email_match(text,frequentWordsCorpusMean,frequentWordsCorpusStdDev):\n",
    "    scores={}\n",
    "    min_score=1000000\n",
    "    min_name=''\n",
    "    zscores=calc_z_score(text,frequentWordsCorpusMean,frequentWordsCorpusStdDev)\n",
    "    for author in zScoresByAuthor:\n",
    "        score=0.0\n",
    "        for word in zScoresByAuthor[author]:\n",
    "            score+=abs(zscores[word]-zScoresByAuthor[author][word])\n",
    "        score/=len(zScoresByAuthor[author])\n",
    "        scores[author]=score\n",
    "        if score<min_score:\n",
    "            min_score=score\n",
    "            min_name=author\n",
    "    return min_name,min_score,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kate.symes@enron.com\n",
      "whadup! i'm so happy for you re: the love thing. love is sooooo in the air \n",
      "lately. molly just fell head over heels for some cowboy dude evan introduced \n",
      "her to. they've been attached at the hips, literally, for the last three \n",
      "weeks. and amber spends about four quality hours a day on the phone with \n",
      "marky, then cries when she has to hang up. seriously. but your romance sounds \n",
      "much more interesting - you absolutely have to keep me posted on how it \n",
      "unfolds. and what's the guy's name anyway? you know what's weird is that last \n",
      "night after my haircut i met up with molly and her man for dinner. we decided \n",
      "to check out the brazen bean, this little swanky cigar bar across the street \n",
      "from the blue moon on 21st. (we heard they had a martini happy hour, and we \n",
      "felt like pretending we were sophisticated.) so we're walking into the place \n",
      "when molly suddenly remembers that she knows the people who live upstairs \n",
      "(it's in one of those old rambling victorian houses) so she runs upstairs to \n",
      "say hi and then comes back down with them. it turns out to be blake and jill, \n",
      "this really sweet couple i've met before, friends of friends, you know how it \n",
      "goes. anyway, we all end up staying longer than we should and having more \n",
      "martinis than we planned on, and then blake remembers his friend dave was \n",
      "coming over to watch a movie. so he runs upstairs to meet dave and brings him \n",
      "back down. well dave happens to be amazingly cute and have amazingly great \n",
      "legs (he had just come from the gym and was amazingly good about sitting in \n",
      "this dimly lit velvet-couched candle-lit shi-shi joint in shorts and a \n",
      "sweatshirt). so dave, molly tells me as she begins to put the hard sell on \n",
      "IMMEDIATELY (i've noticed as i get older and stay single that many of my \n",
      "friends feel the need to try vehemently to get me coupled), plays the guitar \n",
      "amazingly and has an amazing voice. i find out over the course of the evening \n",
      "that he also reads A LOT and is interested in irish literature and quantum \n",
      "physics. well, who isn't, y'know. he also likes to sail - and this is really \n",
      "quite scary - LASER SAILBOATS. yep. i've officially met my father in a \n",
      "younger form. barf. anyway, he and blake and i all had a jolly time talking \n",
      "about books and parents and that show blind date. it was all very \n",
      "intellectual, i assure you. what was weirder still was that every time i said \n",
      "something, dave looked at blake and kind of laughed. and every time i was \n",
      "like, stop your laughing or i'll beat you senseless, and he was like, no i'm \n",
      "just laughing because we were just talking about that the other day or \n",
      "because i've done that or because i'm doing that next week. i said i wanted \n",
      "to start a book club - apparently he suggested that to blake two days ago. i \n",
      "said i lived in italy and wanted to go back - he's going there in two months. \n",
      "oh, and then there's our common love of running. okay, i'm rambling, so i'll \n",
      "get to the point, which is that in my single and cynical state i didn't think \n",
      "much of the poor guy last night, but today i've noticed i'm increasingly \n",
      "interested and, i'll admit, maybe even attracted. so as we were leaving i \n",
      "kind of waved goodbye and said see ya around, because you always do in an \n",
      "incestuous vat such as portland, and went on my merry way with molly and \n",
      "josh, which i'm sure they were happy about since they practically tried to \n",
      "push me into dave's car and run away. dave got in his car and drove off, then \n",
      "all of a sudden appeared in front of us as we were crossing the street to our \n",
      "car. he had driven around the block and was now getting out of his car to \n",
      "give me his card, which he handed to me under the pretense that we couldn't \n",
      "start a book club without each other's contact information. i already knew he \n",
      "worked at a running store, whatever that is, but when i turned the card over \n",
      "it had his name on it and the word \"owner\" underneath. do you think that \n",
      "means he's the actual owner? or is it one of those places like les schwab \n",
      "where they give all the employees stock options and call them \"employee \n",
      "owners\"? i'm going to look into it. now i'm probably making way too much of \n",
      "this because he was probably like, yeah i need some more members for my book \n",
      "club but i definitely don't want to talk to this drinking, smoking, lump of \n",
      "unmolded flesh for any other reason....why would i, the proprietor of a \n",
      "running store and owner of such amazing legs, do a thing like date a girl who \n",
      "shudders at the thought of exercise and loses weight only when she ups her \n",
      "alcohol consumption to the point where she forgets to eat? that would just be \n",
      "silly. okay, i've got to go. get back to me with a detailed account of your \n",
      "evening such as the one i just sent you.\n",
      "\n",
      "kate\n",
      "sally.beck@enron.com 4.4648579850686945\n",
      "{'kay.mann@enron.com': 4.597790230702088, 'vince.kaminski@enron.com': 4.738000188180097, 'jeff.dasovich@enron.com': 4.664457890545814, 'chris.germany@enron.com': 4.72969445983202, 'sara.shackleton@enron.com': 5.1959888453950605, 'tana.jones@enron.com': 4.659651532940156, 'eric.bass@enron.com': 4.7941742054685035, 'matthew.lenhart@enron.com': 4.647720582309997, 'kate.symes@enron.com': 4.615777410710231, 'sally.beck@enron.com': 4.4648579850686945}\n"
     ]
    }
   ],
   "source": [
    "i=2310\n",
    "text=df_test.iloc[i]['FormattedMessage']\n",
    "name=df_test.iloc[i]['From']\n",
    "print(name)\n",
    "print(text)\n",
    "author,min_score,scores=find_email_match(text,frequentWordsCorpusMean,frequentWordsCorpusStdDev)\n",
    "print(author,min_score)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x=np.exp(x-np.max(x))\n",
    "    out=e_x/e_x.sum()\n",
    "    return out\n",
    "\n",
    "def cross_entropy_loss(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray        \n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\n",
    "    return ce\n",
    "\n",
    "def get_probs(text,encoded_classes,frequentWordsCorpusMean,frequentWordsCorpusStdDev):\n",
    "    zscores=calc_z_score(text,frequentWordsCorpusMean,frequentWordsCorpusStdDev)\n",
    "    returnMatrix=[0.0 for author in zScoresByAuthor]\n",
    "    for author in zScoresByAuthor:\n",
    "        score=0.0\n",
    "        for word in zScoresByAuthor[author]:\n",
    "            score+=abs(zscores[word]-zScoresByAuthor[author][word])\n",
    "        score/=len(zScoresByAuthor[author])\n",
    "        for i,item in enumerate(encoded_classes):\n",
    "            if item==author: returnMatrix[i]=score\n",
    "    returnMatrix=[-x for x in returnMatrix]\n",
    "    return softmax(returnMatrix),returnMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chris.germany@enron.com' 'eric.bass@enron.com' 'jeff.dasovich@enron.com'\n",
      " 'kate.symes@enron.com' 'kay.mann@enron.com' 'matthew.lenhart@enron.com'\n",
      " 'sally.beck@enron.com' 'sara.shackleton@enron.com' 'tana.jones@enron.com'\n",
      " 'vince.kaminski@enron.com']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "enc=LabelBinarizer()\n",
    "enc.fit(filter_list)\n",
    "print(enc.classes_)\n",
    "all_text=df_test['FormattedMessage'].tolist()\n",
    "from_list=df_test['From'].tolist()\n",
    "y_values=enc.transform(from_list)\n",
    "y_pred=[]\n",
    "for text in all_text:\n",
    "    prob,blah=get_probs(text,enc.classes_,frequentWordsCorpusMean,frequentWordsCorpusStdDev)\n",
    "    y_pred.append(prob)\n",
    "    \n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris.germany@enron.com\n",
      "Update\n",
      "\n",
      "Jerry and I went to East Texas this weekend.  we withdrew $750.00 from the \n",
      "Fredonia bank and I'm going to deposit that in the Credit Union.  I also took \n",
      "the petty funds in the kitchen drawer - $72.00.\n",
      "\n",
      "AND we did get $2,000.00 deposited into Dad's account from the Credit Union.\n",
      "\n",
      "later dudes\n",
      "chris.germany@enron.com\n",
      "[0.10965931 0.07548288 0.14431942 0.11564122 0.09627069 0.07071252\n",
      " 0.09978375 0.08791403 0.08425849 0.11595769]\n",
      "jeff.dasovich@enron.com\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(from_list[i])\n",
    "print(all_text[i])\n",
    "print(enc.inverse_transform(y_values)[i])\n",
    "print(y_pred[i])\n",
    "print(enc.classes_[np.argmax(y_pred[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.39284038838596\n"
     ]
    }
   ],
   "source": [
    "print(cross_entropy_loss(y_values,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
